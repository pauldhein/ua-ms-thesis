\chapter{INTRODUCTION\label{chapter:introduction}}
Scientific models are increasingly expressed as executable software.
This enables a host of opportunities, including the following:
\begin{itemize}
\item increased precision in predictions,
\item the possibility of better control over reproducibility of results,
\item better communication of model details through unambiguous code implementation, and
\item the potential to aggregate individual models from different domains into larger multi-domain models.
\end{itemize}
These advantages have been the driving force that has pushed the scientific community towards computational models as a method of communicating scientific research.
Now that these models-as-software are becoming the common currency of scientific discourse and methodology, we have new opportunities as well as challenges in order to realize the potential of large-scale computationally-supported science.
In particular, we need tools to help domain scientists better understand how their scientific model software implementations behave and how models relate to one another..

Consider the following simple example of computational model comparison. Figure~\ref{fig:simple_crop_CAG} depicts two models that both describe how some value of interest, crop \emph{Yield}, is computed. The two models are expressed as \emph{computation graphs}, where nodes represent variables and directed arcs represent a functional relationship between variables (this representation will be described in more detail in Chapter~\ref{chapter:extraction}).
Both models describe how the yield of a particular crop is affected by changes in the amount of rain and soil water absorption rate over time (expressed in \emph{Day}s).

\begin{figure}[!htbp]
  \label{fig:simple_crop_CAG}
  \centering
  \tikz{ % Simple Crop Yield model example
    \tikzstyle{readable}=[rectangle, thick, rounded corners]
    \node[latent, readable] (crop_yield) {$Yield$} ; %
    \node[latent, readable, above=of crop_yield] (total_rain) {$Rain_{total}$} ; %
    \node[latent, readable, above=of total_rain] (rain) {$Rain$} ; %
    \node[obs, readable, above=of rain] (max_rain) {$Rain_{max}$} ; %
    \node[obs, readable, left=of max_rain] (absorption) {$Absorption$} ; %
    \node[obs, readable, right=of max_rain] (consistency) {$Consistency$} ; %
    \node[obs, readable, right=of rain] (day) {$Day$} ; %
    \edge {day, consistency, absorption, max_rain} {rain} ; %
    \edge {rain} {total_rain} ; %
    \path [->] (total_rain) edge  [loop right] (total_rain);
    \edge {total_rain} {crop_yield} ; %

    \plate {loop} {(rain)(day)(total_rain)} {$Day$} ;
  }
  \tikz{ % Different Crop Yield model example
    \tikzstyle{readable}=[rectangle, thick, rounded corners]
    \node[latent, readable] (crop_yield) {$Yield$} ; %
    \node[latent, readable, above=of crop_yield] (total_rain) {$Rain_{total}$} ; %
    \node[latent, readable, above=of total_rain] (rain) {$Rain$} ; %
    \node[obs, readable, above=of rain] (max_rain) {$Rain_{max}$} ; %
    \node[obs, readable, right=of max_rain] (absorption) {$Absorption$} ; %
    \node[obs, readable, left=of rain] (consistency) {$Consistency$} ; %
    \node[obs, readable, left=of total_rain] (sunlight) {$Sunlight$} ; %
    \node[obs, readable, right=of rain] (day) {$Day$} ; %
    \edge {day, absorption, max_rain} {rain} ; %
    \edge {rain, consistency} {total_rain} ; %
    \path [->] (total_rain) edge  [loop right] (total_rain);
    \edge {total_rain, sunlight} {crop_yield} ; %

    \plate {loop} {(rain)(day)(total_rain)} {$Day$} ;
  }
  \caption[Competing Models of Crop Yield]{Two competing scientific models depicting the affects of rain on the yield of a crop over a span of days given some other inputs. We see that the two models share many of their inputs but that some inputs may not be shared and the wiring of the inputs to the output variable can differ between the models.}
\end{figure}

Both of these models have sets of input variables (shaded) and both compute the same output value.
Upon observing the inputs through measurement, a value for the output can be computed.
Although these models share some of the same variables, there are important differences, namely that one has an additional input and that the internal wirings of the variables in the two models differ.
The models could differ even more than this, in fact it is possible for competing models to only share the same output node.
Given these two models, a crop modeling domain expert is interested in understanding how these models behave and what their similarities and differences are.
In general, the domain expert is engaged in a model selection task, where they are trying to determine whether one, or possibly neither, of these models is appropriate for their modeling task, where they are using these models to try to predict or explain some aspect of the world.

Performing comparisons between competing models requires the ability to identify how different models utilize information from their inputs.
For models that are defined in source code, an easy way to identify these differences is by comparing and analyzing the model computation graphs.
Since most competing models that exist in source code are likely written in different programming languages, any modeler who wants to compare and analyze the computation graphs of competing models will need to perform a translation task that will translate all of the competing models into a single representation language.
This representation language needs to enhance the representation of models found in the source code by associating the variables found in the source code models with the aspects of the modeled domain that they correspond to.
Accomplishing this would allow the shared variables between competing models defined in source code to be identified.
After completing these tasks a modeler would then be able to undertake the task of performing a direct comparison and analysis of how the competing models are similar and different, and either one, or possibly none, is a good choice for the modeling application.

\section{Problem Scope and Contributions\label{sec:prob_scope}}
This thesis describes a set of related data structures and algorithms that are part of a framework aimed at automating key tasks enabling the analysis of scientific models implemented in software, with a particular focus on enabling software model comparison for model analysis and selection. This thesis makes the following four contributions:

\begin{enumerate}
  \item Uses the results of a program analysis processing pipeline that extracts models from scientific model source code to represent the model in a programming language-agnostic representation that supports general model analysis.
  \item An algorithm to identify model structural overlap, as a basis for identifying how models are structurally similar and different.
  \item An algorithm for searching for input value ranges that make overlapping models behave as close to each other as possible, and thereby also identify value ranges that distinguish models (a basis for experiment design).
  \item Adaptation of sensitivity analysis measures to identify model output sensitivity as a function of model input value ranges within a uniform analysis framework.
\end{enumerate}

Combining these capabilities into a single framework provides a facility for domain-expert model developers and analysts to now analyze and compare models within a uniform framework, greatly simplifying model analysis tasks that to-date have required enormous manual effort.
This system described here does not take the human out of the loop: domain expertise and human guidance are still needed to identify variable value ranges of interest to a modeling application, as well as supplement mistakes of omission and commission that may be made during variable grounding.
Ongoing and future development is also required to scale the methods to effectively handle larger model code bases.
However, this framework described here is, to our knowledge, the first general approach to automating aspects of model analysis in the support of general model comparison and selection.
We also believe these tools provide a basis for a new kind of model curation and debugging, allowing one to compare changes within evolving code bases but from a modeling domain-semantics perspective. Exploring use of this framework for this purpose will be the subject of future work.

The set of algorithms I describe in this thesis comprise what I call the \emph{Scientific Model Selection} (SMS) pipeline: a system that provides a set of tools to help with the comparison and selection of models extracted from source code.
To accomplish this task the system must be able to extract scientific models from source code, ground the real-world variables contained in the models using information gained from associated texts, and finally perform the model selection task using information gained from sensitivity analysis.
The SMS pipeline is a component of the larger software system designed as part of the DARPA funded Automated Model Assembly from Text Equations and Software (AutoMATES\footnote{\url{https://ml4ai.github.io/automates/}}) project \citep{pyarelal2019}.

As a component of the AutoMATES project, this pipeline focuses on part of the overall goal of model extraction, grounding, and analysis.
The AutoMATES project includes three additional modules that all provide input to the SMS pipeline.
These modules are the Program Analysis (PA) pipeline, the Text Reading (TR) module, and the Equation Reading (ER) module.
The inputs provided by these modules will assist the SMS pipeline in extracting abstract representations of source code from the original source code languages, as well as grounding the variables found in that source code to real-world concepts.
Any inputs to the SMS pipeline from these modules will be documented in the sections of the thesis where they are used.

\section{Roadmap\label{sec:this_work}}
This thesis is organized to present the components of the pipeline that will solve the problem presented in the problem scope section.
During the course of this thesis I will use two models from the Decision Support System for Agrotechnology Transfer (DSSAT)\footnote{\url{https://dssat.net/}} software system \citep{DSSAT}.
The models used in this study will be targeting the natural phenomena of Potential Evapo-Transpiration (PET).
The specific models I will be comparing are the Priestly-Taylor model of Potential Evapo-Transpiration (PETPT) and the ASCE model of Potential Evapo-Transpiration (PETASCE).
Chapter~\ref{chapter:umaf} will introduce the algorithms used to extract models from source code and transform them into a form that is both executable and comparable across competing models.
Chapter~\ref{chapter:umaf} will also introduce the analysis methods used by the SMS pipeline to derive information about the models under comparison.
Chapter~\ref{chapter:analysis_studies} will document how the derived information from the analysis phase can be used to perform automated model selection, as well as how the information will be presented to users of the SMS pipeline to allow them to make their own final model selection decisions.
Finally, Chapter~\ref{chapter:conc_and_future} concludes with a discussion of the results and implications of the pipeline and will introduce possible extensions for continuing this research.
